<img class="aligncenter wp-image-1323072 size-large" src="https://i0.wp.com/www.vanguardngr.com/wp-content/uploads/2020/01/YouTube.jpg?resize=640%2C427&#038;ssl=1" alt="YouTube" width="640" height="427" data-recalc-dims="1" /> YouTube said Monday it would remove election-related videos that are “manipulated or doctored” to mislead voters, as part of its efforts to stem online misinformation. The Google-owned video service said it was taking the measures as part of an effort to be a “more reliable source” for news and to promote a “healthy political discourse.” Leslie Miller, YouTube’s vice president of government affairs and public policy, said in a blog post that the service’s community standards prohibit “content that has been technically manipulated or doctored in a way that misleads users … and may pose a serious risk of egregious harm.” The policy also bans content which aims to mislead people about voting or the census processes. The move comes amid growing concern about so-called “deepfake” videos altered by using artificial intelligence which can create credible-looking events, but also “shallow” fakes that use more rudimentary techniques to deceive viewers. Online platforms have come under pressure to root out misinformation in the wake of a foreign manipulation effort in the 2016 US elections and claims that not enough is being done to curb false claims by candidates themselves. – Concerns over US campaign –
The latest YouTube statement, which seeks to clarify a policy on misinformation, comes as the US presidential primary kicks off which caucuses being held in Iowa on Monday and the first primary next week in New Hampshire. Google last year said it was stepping up efforts on election misinformation and would remove false claims in ads, including on YouTube. “The underlying standards YouTube explains and illustrates today do not appear to be brand new, but the company deserves praise for setting them out in clear terms and warning that it intends to enforce them vigorously,” said Paul Barrett of the New York University Center for Business and Human Rights and author of a 2019 study on political disinformation. READ ALSO: Man climbing Mount Fuji fell off while live-streaming on YouTube “YouTube’s statement today appears to reiterate its determination not to allow its users to be conned during the 2020 election campaign.” The announcement underscores differing policies by major social networks on disinformation. Twitter has said it would ban all political ads for candidates, while Facebook has maintained a hands-off policy for political speech and ads, with some exceptions for content that misleads users about voting times and places. “Each platform is weighing free expression against voter manipulation but the information operations work across platforms and exploit these loopholes,” said Karen Kornbluh, a German Marshall Fund researcher who follows political disinformation. “That’s why the platforms should come together and develop shared, clear, consistent, enforceable rules to protect voters from becoming easy marks for disinformation campaigns.” Monday’s statement offered specific examples of content that would be removed from YouTube. Among the content banned include any video “manipulated to make it appear that a government official is dead” or which “aims to mislead people about voting or the census processes, like telling viewers an incorrect voting date.” YouTube will also take down any false claims about eligibility requirements for political candidates “such as claims that a candidate is not eligible to hold office based on false information about citizenship status requirements.” A separate statement by Google’s head of online trust and safety, Kristie Canegallo, said the internet giant has stepped up its efforts to stem abuse and false information on election content. “Our trust and safety teams span the globe to monitor and disrupt account hijackings, inauthentic activity, disinformation campaigns, coordinated attacks, and other forms of abuse on our platforms on a 24/7 basis,” Canegallo said. “We take seriously our responsibility to protect our users from harm and abuse, especially during elections.” She added that Google is working with other technology companies and government agencies including the FBI “to identify bad actors, disable their accounts, warn our users about them, and share relevant information with industry officials and law enforcement.” VANGUARD EVEN as reactions by patriotic and objective observers have shown, not many Nigerians are surprised or can easily be deceived by the pranks of the emerging phenomenon of fake news in the country January 15, 2019 In "News" Facebook has announced that it had removed a set of 265 Facebook and Instagram assets, created by a Tel Aviv, Israel-based Archimedes Group for interfering with elections, which included the recent Nigeria’s February/March 2019 general elections. May 19, 2019 In "News" Google is to deploy a staff of 10,000 to hunt down extremist content on its YouTube platform following recent criticism, the video-sharing site's chief executive told Britain's Daily Telegraph Tuesday. December 5, 2017 In "Technology"